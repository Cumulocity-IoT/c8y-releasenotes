---
weight: 40
title: Release 10.15.0
layout: bundle
---

Cumulocity IoT DataHub Release 10.15 includes the following improvements, limitations, and known issues:

### New version of internal query engine

Cumulocity IoT DataHub now uses version 22 of Dremio as its query engine. The new version comes with various enhancements and improvements including performance improvements and optimized data lake access.

### Change of data lake credentials

When setting up Amazon S3 or Azure Storage as data lake for Cumulocity IoT DataHub, a corresponding access secret or access key is defined. These access credentials may change over time. Prior to this release, updating the credentials required to delete and reconfigure all settings. With this release, the access credentials can be changed without deleting and reconfiguring settings. 

### Additional Dremio users

When setting up Cumulocity IoT DataHub, a Dremio user is created. This user can be used in applications to run SQL queries against the data lake via Dremio. With this release, additional Dremio users for running queries can be created and managed using Cumulocity IoT DataHub.

### Mixed type coercion 

Prior to DataHub 10.15, if an attribute of a collection had varying types associated, the result table would contain a mixed-type column, leading to problems with applications consuming the data over JDBC/ODBC. With 10.15 mixed-type columns are now automatically coerced to a generic type that can represent all involved types. For example, if a mixture of integer and floating point values is given, it will coerce to float. In most cases, data will be coerced to varchar/string as generic type.

### ODBC driver based on Apache Arrow Flight

Dremio 22 supports a more efficient way of retrieving data via ODBC. The corresponding [ODBC driver](https://www.dremio.com/drivers/odbc/) internally uses Apache Arrow Flight, leading to a slightly differing [connection string](https://docs.dremio.com/software/drivers/arrow-flight-sql-odbc-driver/). Most importantly port 32010 (default) is used instead of 31010 (default). The "legacy" ODBC driver continues to work using port 31010.  

The "ODBC connection" quick setup dialog in the DataHub UI does not reflect this yet, it describes how to connect using the "legacy" driver.

### PowerBI web integration without PowerBI Gateway 

Dremio 20.1 and newer in combination with PowerBI June 2022 or newer enables direct connections from PowerBI Service to Dremio, without the need for a PowerBI Gateway. Details can be found in the corresponding [Direct Connect documentation](https://docs.dremio.com/software/client-applications/microsoft-power-bi/#direct-connect).

### Limitations

|<div style="width:250px">Description</div>
|:---
|Mixed usage of uppercase and lowercase characters for an attribute name as well as series names in the documents is not supported.|
|If the collection to be offloaded has JSON attributes consisting of more than 32,000 characters, its data cannot be offloaded. One specific case where this limitation applies is Cumulocity IoT's application builder, which stores its assets in the inventory collection when being used.|
|If the collection to be offloaded has more than 800 JSON attributes, its data cannot be offloaded. This limitation also includes nested JSON content, which will be expanded into columns during offloading. Therefore, measurements documents with more than 800 series/series value fragments are not supported.|

### Known issues

|<div style="width:250px">Edition|Description|
|:---|:---|
|Cloud|Data lake configuration validation is broken in terms of wrong bucket names (AWS S3) and wrong account names (Azure Storage). When saving the settings with an invalid bucket/account name, DataHub fails to quickly detect the problem and will instead run a time-consuming check, which shows up as an ongoing save request in the UI. Eventually the request will fail in the UI with a timeout and the save request in the backend will fail as well. In such a case, please carefully check the bucket/account name and try saving again.|
|Edge|There are no retention policies in place that prevent the data lake contents from exceeding the hard disk limits.|
|Edge|TLS is not supported for ODBC and JDBC.|
